{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DecisionTree.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MangoHaha/MLFromScratch/blob/master/DecisionTree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyEPOi7Ms9Be",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "53710bb8-1e8e-4877-8f6b-dd3c9582d614"
      },
      "source": [
        "!pip install sklearn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import sys\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.21.3)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.16.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.13.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0Lu0ZpjtGS_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "d0fee0e3-81f2-4d1b-c4a5-d55b243965e7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LK_OCfqtRub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/MLFromScratch')\n",
        "sys.path.insert(0,\"./utils\")\n",
        "\n",
        "from data_manipulation import divide_on_feature\n",
        "from data_manipulation import train_test_split, standardize\n",
        "from data_operation import calculate_entropy, accuracy_score\n",
        "from data_operation import mean_squared_error, calculate_variance\n",
        "from principal_component_analysis import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gO8cLCEwqaa",
        "colab_type": "text"
      },
      "source": [
        "Gini impurity and Information Gain Entropy are pretty much the same. And people do use the values interchangeably. Below are the formulae of both:\n",
        "\n",
        "1.compute the entropy for data-set\n",
        "\n",
        "2.for every attribute/feature:\n",
        "\n",
        "       1.calculate entropy for all categorical values\n",
        "       2.take average information entropy for the current attribute\n",
        "       3.calculate gain for the current attribute\n",
        "       \n",
        "3. pick the highest gain attribute.\n",
        "4. Repeat until we get the tree we desired.\n",
        "\n",
        "Gini:Gini(ùê∏)=1‚àí‚àëpi^2\n",
        "\n",
        "Minimum value of Gini Index will be 0 when all observations belong to one label.\n",
        "Maximum value of Gini Index could be 0.5 when all target values are equally distributed.\n",
        "Favors larger partitions.\n",
        "Uses squared proportion of classes.\n",
        "Perfectly classified, Gini Index would be zero.\n",
        "Evenly distributed would be 1 ‚Äì (1/# Classes).\n",
        "You want a variable split that has a low Gini Index.\n",
        "The algorithm works as 1 ‚Äì ( P(class1)^2 + P(class2)^2 + ‚Ä¶ + P(classN)^2)\n",
        "\n",
        "\n",
        "Entropy:ùêª(ùê∏)=‚àí‚àëPilogPi\n",
        "\n",
        "Information gain: the expected information gain is the change in information entropy Œó from a prior state to a state that takes some information as given \n",
        "\n",
        "Favors splits with small counts but many unique values.\n",
        "Weights probability of class by log(base=2) of the class probability\n",
        "A smaller value of Entropy is better.  That makes the difference between the parent node‚Äôs entropy larger.\n",
        "Information Gain is the Entropy of the parent node minus the entropy of the child nodes.\n",
        "Entropy is calculated [ P(class1)*log(P(class1),2) + P(class2)*log(P(class2),2) + ‚Ä¶ + P(classN)*log(P(classN),2)]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2qg5BzdtkDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TreeNode():\n",
        "    def __init__(self, feature_index, split_val, groups, gini):\n",
        "        self.left=None\n",
        "        self.right=None\n",
        "        self.feature_index=feature_index\n",
        "        self.split_val=split_val \n",
        "        self.gini=gini\n",
        "        self.groups=groups #[left/right gourps]\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrL24sGiuJaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecisionTree():\n",
        "    def __init__(self, max_depth=5, min_size=1):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_size  = min_size\n",
        "        \n",
        "        \n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.y = y\n",
        "        self.X = X\n",
        "        self.num_features = np.shape(X)[1]\n",
        "        self.class_values = [set(y)]\n",
        "        self.root = self._get_root_node([i for i in range(len(X))])\n",
        "        self._build_tree(self.root,1)\n",
        "\n",
        "    def _get_root_node(self, idxs):\n",
        "      best_score = sys.maxsize\n",
        "      best_node = None\n",
        "      #loop through each entry, and each feature val\n",
        "      for index in range(self.num_features - 1):\n",
        "        for idx in idxs:\n",
        "          groups = self._split_dataset(index, self.X[idx][index], idxs)\n",
        "          gini = self._calculate_gini(groups, self.class_values)\n",
        "          if(gini < best_score):\n",
        "            best_score = gini\n",
        "            best_node = TreeNode(index, self.X[idx][index], groups, gini)\n",
        "      return best_node\n",
        "                         \n",
        "    #split a dataset based on an attribute and and attribute value\n",
        "    def _split_dataset(self, index, value, idxs):\n",
        "      #split list of idxs, into two groups based on value and feature_index\n",
        "      left = []\n",
        "      right= []\n",
        "      for idx in idxs:\n",
        "        if(self.X[idx][index] < value):\n",
        "          left.append(idx)\n",
        "        else:\n",
        "          right.append(idx)\n",
        "      return [left, right]\n",
        "   \n",
        "    #calcualte geni index for a split dataset\n",
        "    \"\"\"\n",
        "    gini_index = sum(proportion * (1.0 - proportion)) = 1.0 - sum(proportion * proportion)\n",
        "    \n",
        "    \"\"\"\n",
        "    def _calculate_gini(self, groups, classes):\n",
        "        #dat: [1,2,3] classes [0,0,1]\n",
        "        #group 1 [1,2] label: 0; group2 [3] label: 1\n",
        "        #count all samples at split point\n",
        "        num_instances = float(sum(len(group) for group in groups))\n",
        "        gini = 0.0\n",
        "        #calculate gini for each group, then add weighted val\n",
        "        for group in groups:\n",
        "          size = float(len(groups))\n",
        "          #avoid divided by zero\n",
        "          if size == 0:\n",
        "            continue;\n",
        "          score = 0.0\n",
        "          #calculate each score based for each class of label\n",
        "          for label in classes:\n",
        "            prob = [self.y[idx] for idx in group].count(label)*1.0/size\n",
        "            score += prob**2.0\n",
        "          #weight the groups score by size\n",
        "          gini += (1.0 - score) * (size/num_instances)\n",
        "        return gini\n",
        "      \n",
        "    def _build_tree(self, root, depth=0):\n",
        "      left, right = root.groups\n",
        "      #if any either group get all, another get nothing, there is no meaning to \n",
        "      #split further, since if you split further, the split critria is still gini\n",
        "      #index, you will get the same split.\n",
        "      if(len(left) == 0 or len(right) == 0):\n",
        "        root.left = root.right = self._terminal(left + right)\n",
        "        return\n",
        "      \n",
        "      if depth >= self.max_depth:\n",
        "        root.left = self._terminal(left)\n",
        "        root.right = self._terminal(right)\n",
        "      \n",
        "      root.left = self._get_root_node(left)\n",
        "      self._build_tree(root.left, depth+1)\n",
        "      root.right = self._get_root_node(right)\n",
        "      self._build_tree(root.right, depth+1)\n",
        "      return root\n",
        "    #create a terminal node value (leaf node stores predicted outcome)\n",
        "    def _terminal(self, group):\n",
        "        #print(group)\n",
        "        outcomes = [self.y[idx] for idx in group]\n",
        "        #print(outcomes)\n",
        "        #print(max(set(outcomes), key=outcomes.count))\n",
        "        return max(set(outcomes), key=outcomes.count)\n",
        "      \n",
        "    def predict_one(self, x):\n",
        "        node = self.root\n",
        "        while isinstance(node, TreeNode):\n",
        "            split_index = node.feature_index\n",
        "            split_value = node.split_val\n",
        "            if x[split_index] < split_value:\n",
        "                node = node.left\n",
        "            else:\n",
        "                node = node.right\n",
        "        return node\n",
        "\n",
        "    def predict(self, X):\n",
        "        preds = []\n",
        "        for x in X:\n",
        "          preds.append(self.predict_one(x))\n",
        "        #labels = map(self.predict_one, X)\n",
        "        return preds\n",
        "     \n",
        "    def print_tree(self, node, depth=0):\n",
        "        if isinstance(node, TreeNode):\n",
        "            print(\"{} split feature{} at value {} with gini score of {}\".format(depth*\" \", node.feature_index, node.split_val,node.gini))\n",
        "            self.print_tree(node.left,depth+1)\n",
        "            self.print_tree(node.right,depth+1)\n",
        "        else:\n",
        "            print(\"{} {}\".format(depth*\" \", node))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjQ_kpAlT0ZY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "8889a8f9-13c3-4ee3-df66-4d33e3be6a36"
      },
      "source": [
        "iris = datasets.load_iris()\n",
        "X = iris.data[:, :2]\n",
        "y = (iris.target != 0) * 1\n",
        "model = DecisionTree()\n",
        "model.fit(X,y)\n",
        "preds = model.predict(X)\n",
        "print(preds)\n",
        "model.print_tree(model.root)\n",
        "accuracy = accuracy_score(y.tolist(), preds)\n",
        "  \n",
        "print (\"Accuracy:\", accuracy)\n"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " split feature0 at value 5.1 with gini score of 0.02666666666666667\n",
            "  split feature0 at value 4.9 with gini score of 0.125\n",
            "   split feature0 at value 4.7 with gini score of 0.25\n",
            "    split feature0 at value 4.6 with gini score of 0.4444444444444444\n",
            "     split feature0 at value 4.4 with gini score of 0.8\n",
            "      split feature0 at value 4.3 with gini score of 4.0\n",
            "       0\n",
            "       0\n",
            "      split feature0 at value 4.4 with gini score of 1.0\n",
            "       0\n",
            "       0\n",
            "     split feature0 at value 4.6 with gini score of 1.0\n",
            "      0\n",
            "      0\n",
            "    split feature0 at value 4.7 with gini score of 0.5714285714285714\n",
            "     0\n",
            "     0\n",
            "   split feature0 at value 4.9 with gini score of 0.25\n",
            "    0\n",
            "    0\n",
            "  split feature0 at value 5.1 with gini score of 0.03389830508474576\n",
            "   1\n",
            "   1\n",
            "Accuracy: 0.8266666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTMQ_jAcc-ay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}